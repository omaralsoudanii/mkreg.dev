# run with nginx user
user nginx;
# enable PCRE JIT compiler for faster location blocks parsing
# https://nginx.org/en/docs/ngx_core_module.html#pcre_jit
pcre_jit on;


error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

# CPU cores : cat /proc/cpuinfo | grep 'processor' | wc -l
# if there is a backend in the same server, don't let nginx take all cores.
# we let nginx take 2 cores to serve proxies, but with hyper-threading
worker_processes 2;


# Bind worker processes to a set of CPU
# Do your reasearch about CPU affinity before adjusting the defaults
# https://nginx.org/en/docs/ngx_core_module.html#worker_cpu_affinity
worker_cpu_affinity 0101 1010;


# Deciding worker_rlimit_nofile and worker_processes values
# First, read about linux ulimits systemd, selinux and how it applies to docker before tuning this settings
# https://serverfault.com/questions/787919/optimal-value-for-nginx-worker-connections
# https://github.com/digitalocean/nginxconfig.io/blob/ae322cf2c5c070164d18ccec55cf764cca058acf/README.md#-resources
# set for each worker process separately
# e.g: worker_processes = 5 | worker_connections = 10000
# then worker_rlimit_nofile = worker_connections * 5 = 50000
# multiply by 2 because we use it as a reverse proxy, incase static serving then don't multiply
# THANKS TO NGINX CRYSTAL CLEAR DOCS I'M STILL NOT SURE ABOUT THIS (YES CAPS, READ THE DOCS AND YOU WILL UNDERSTAND)
# closest answer: https://stackoverflow.com/questions/37591784/nginx-worker-rlimit-nofile#comment115694619_58275474
# 8096 * 2 = 16192
worker_rlimit_nofile 16192;

events {
    # This should be derived from worker_rlimit_nofile, not the other way around
    # Read about `ulimit -Sn` and `ulimit -Hn` and `ulimit -a` then change accordingly.
    # After your system crash because you set a value your server can't handle, come blame meâ€”or even better blame nginx
    # i.e. if worker_rlimit_nofile is 2048 and NGINX is acting as reverse proxy (each connection open 2 files)
    # then worker_connections = 2048 / 2 = 1024
    # if static then we open 1 file so it would be 2048 / 1 = 2048
    worker_connections 8096;
    multi_accept off;
    use epoll;
    # https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/
    accept_mutex off;
}

http {
    # mime.types is in /etc/mime.types?
    # pathing here is different due to docker we copied the config files in the same dir
    include mime.types;
    # Yeah that bugs some times
    default_type application/octet-stream;
    charset utf-8;
    charset_types text/css
    text/markdown
    application/javascript
    image/apng
    image/gif
    image/jpeg
    image/png
    image/svg+xml
    application/xml+rss
    application/json
    font/woff
    font/woff2
    image/webp
    image/x-icon
    application/manifest+json;

    log_format  main  '[$time_local] - [$http_cf_ipcountry] - $host- $http_x_forwarded_for - $remote_user "$request" '
    '[$status] $body_bytes_sent "$http_referer" '
    '"$http_user_agent"';

    access_log /var/log/nginx/access.log main;
    # Cloudflare
    resolver 1.1.1.1;
    # Real IP CF
    set_real_ip_from 103.21.244.0/22;
    set_real_ip_from 103.22.200.0/22;
    set_real_ip_from 103.31.4.0/22;
    set_real_ip_from 104.16.0.0/12;
    set_real_ip_from 108.162.192.0/18;
    set_real_ip_from 131.0.72.0/22;
    set_real_ip_from 141.101.64.0/18;
    set_real_ip_from 162.158.0.0/15;
    set_real_ip_from 172.64.0.0/13;
    set_real_ip_from 173.245.48.0/20;
    set_real_ip_from 188.114.96.0/20;
    set_real_ip_from 190.93.240.0/20;
    set_real_ip_from 197.234.240.0/22;
    set_real_ip_from 198.41.128.0/17;
    set_real_ip_from 2400:cb00::/32;
    set_real_ip_from 2606:4700::/32;
    set_real_ip_from 2803:f800::/32;
    set_real_ip_from 2405:b500::/32;
    set_real_ip_from 2405:8100::/32;
    set_real_ip_from 2c0f:f248::/32;
    set_real_ip_from 2a06:98c0::/29;
    real_ip_header CF-Connecting-IP;

    open_file_cache max=200000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    # don't write to disk
    proxy_request_buffering off;

    # copies data between one FD and other from within the kernel
    # faster than read() + write()
    sendfile on;

    # send headers in one piece, it is better than sending them one by one
    tcp_nopush on;

    # don't buffer data sent, good for small data bursts in real time
    tcp_nodelay on;

    # allow the server to close connection on non responding client, this will free up memory
    reset_timedout_connection on;

    # request timed out -- default 60
    client_body_timeout 10;

    # if client stop responding, free up memory -- default 60
    send_timeout 2;

    # server will close connection after this time -- default 75 -- maybe you prefer higher but I prefer lower
    keepalive_timeout 20;

    # These are what we call a NGINX config directives that I'm too lazy to explain
    # here https://nginx.org/en/docs/
    sendfile_max_chunk 512k;
    server_tokens off;
    server_name_in_redirect off;
    server_names_hash_max_size 512;
    server_names_hash_bucket_size 512;

    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=mk_cache:128m max_size=5g inactive=3d use_temp_path=off;

    include /etc/nginx/compression.conf;
    include /etc/nginx/conf.d/*.conf;
}

